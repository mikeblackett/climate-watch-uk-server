{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import datetime as dt\n",
    "import os\n",
    "\n",
    "# Third-party libraries\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Local libraries\n",
    "from utilities import netcdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "ROOT_DIR = os.path.join(os.getcwd(), \"data\")\n",
    "HAD_DIR = os.path.join(ROOT_DIR, \"intermediate/hadukgrid/monthly-1km\")\n",
    "OUT_DIR = os.path.join(ROOT_DIR, \"processed/climate\")\n",
    "OUT_DIR_MONTHLY = os.path.join(OUT_DIR, \"monthly\")\n",
    "OUT_DIR_ANNUAL = os.path.join(OUT_DIR, \"annual\")\n",
    "OUT_DIR_SEASONAL = os.path.join(OUT_DIR, \"seasonal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1km climate data\n",
    "nc_files_1km = netcdf.list_files(HAD_DIR, path=True)\n",
    "\n",
    "# Locations geo data\n",
    "location = gpd.read_file(\n",
    "    os.path.join(ROOT_DIR, \"processed/location\", \"location.geojson\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_code(month_number):\n",
    "    \"\"\"Returns the corresponding season code for a month number\"\"\"\n",
    "    if month_number in [12, 1, 2]:\n",
    "        return \"win\"\n",
    "    if month_number in [3, 4, 5]:\n",
    "        return \"spr\"\n",
    "    if month_number in [6, 7, 8]:\n",
    "        return \"sum\"\n",
    "    if month_number in [9, 10, 11]:\n",
    "        return \"aut\"\n",
    "\n",
    "\n",
    "def to_table(ds, data_var):\n",
    "    \"\"\"Converts spatially aggregated HadUK-Grid DataSet to a pandas DataFrame formatted for the CWUK databse\"\"\"\n",
    "    df = (\n",
    "        ds[data_var]\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            columns={\n",
    "                data_var: \"value\",\n",
    "                \"location\": \"location_id\",\n",
    "                \"month_number\": \"month\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    df[\"year\"] = df.apply(\n",
    "        lambda row: int(row[\"time\"].date().strftime(\"%Y\")), axis=1\n",
    "    )\n",
    "    df[\"season\"] = df.apply(lambda row: get_season_code(row[\"month\"]), axis=1)\n",
    "    df.insert(loc=0, column=\"variable_id\", value=[data_var] * len(df))\n",
    "    df = df.drop(columns=\"time\")\n",
    "    df = df[\n",
    "        [\n",
    "            \"variable_id\",\n",
    "            \"location_id\",\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"value\",\n",
    "            \"season_year\",\n",
    "            \"season\",\n",
    "        ]\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_mask(gdf, da):\n",
    "    \"\"\"\n",
    "    Returns a array of spatial masks with values clipped to the geometries in `gdf`.\n",
    "    One mask for each row of `gdf`.\n",
    "    \"\"\"\n",
    "    mask_da = xr.ones_like(da)\n",
    "    mask_da.name = \"mask\"\n",
    "    mask_da = mask_da.rio.write_crs(da.rio.crs)\n",
    "\n",
    "    return xr.concat(\n",
    "        [\n",
    "            (mask_da.rio.clip([item.geometry], drop=False) == 1).expand_dims(\n",
    "                dim={\"location\": [item.id]}\n",
    "            )\n",
    "            for item in gdf.itertuples()\n",
    "        ],\n",
    "        dim=\"location\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_COORD = \"projection_y_coordinate\"\n",
    "X_COORD = \"projection_x_coordinate\"\n",
    "\n",
    "for fp in nc_files_1km:\n",
    "    with xr.open_dataset(fp, decode_coords=\"all\", chunks=\"auto\") as ds:\n",
    "        # Each nc file has a single data variable\n",
    "        DATA_VAR = list(ds.data_vars)[0]\n",
    "        # Create spatial masks. One for each location\n",
    "        mask_da = create_mask(location, ds[DATA_VAR])\n",
    "        # Calculate the mean for each location\n",
    "        mean_da = ds.where(mask_da).mean([Y_COORD, X_COORD])\n",
    "        # Collect names of coords to drop before calling to_table()\n",
    "        coords_to_drop = []\n",
    "        for coord in mean_da.coords:\n",
    "            if coord not in [\n",
    "                DATA_VAR,\n",
    "                \"time\",\n",
    "                \"month_number\",\n",
    "                \"year\",\n",
    "                \"season_year\",\n",
    "                \"location\",\n",
    "            ]:\n",
    "                coords_to_drop.append(coord)\n",
    "        df_monthly = to_table(mean_da.drop(coords_to_drop), DATA_VAR)\n",
    "\n",
    "        # Seasonal aggregation\n",
    "        df_seasonal = (\n",
    "            df_monthly[\n",
    "                [\"variable_id\", \"location_id\", \"season_year\", \"season\", \"value\"]\n",
    "            ]\n",
    "            .groupby([\"season_year\", \"season\", \"location_id\", \"variable_id\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        df_seasonal = df_seasonal.rename(columns={\"season_year\": \"year\"})\n",
    "        # Annual aggregation\n",
    "        df_annual = (\n",
    "            df_monthly[[\"variable_id\", \"location_id\", \"year\", \"value\"]]\n",
    "            .groupby([\"year\", \"location_id\", \"variable_id\"])\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "        # Save to disk\n",
    "        df_monthly.to_csv(\n",
    "            os.path.join(OUT_DIR_MONTHLY, DATA_VAR + \"-monthly\" + \".csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        df_seasonal.to_csv(\n",
    "            os.path.join(OUT_DIR_SEASONAL, DATA_VAR + \"-seasonal\" + \".csv\"),\n",
    "            index=False,\n",
    "        )\n",
    "        df_annual.to_csv(\n",
    "            os.path.join(OUT_DIR_ANNUAL, DATA_VAR + \"-annual\" + \".csv\"),\n",
    "            index=False,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('climate-watch-uk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:36:39) [GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c854546abfe7675fb91040f7a9b26eea616d985cf4a026000aaaf57beb5b71ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
